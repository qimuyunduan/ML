{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/matplotlib/tight_layout.py:222: UserWarning: tight_layout : falling back to Agg renderer\n  warnings.warn(\"tight_layout : falling back to Agg renderer\")\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from pandas import DataFrame\n",
    "\n",
    "#使用make_classification构造1000个样本，每个样本有20个feature\n",
    "X, y = make_classification(1000, n_features=20, n_informative=2,\n",
    "                           n_redundant=2, n_classes=2, random_state=0)\n",
    "\n",
    "#存为dataframe格式\n",
    "# y[:, None] 把y转化为1000*1的矩阵\n",
    "df = DataFrame(np.hstack((X, y[:, None])),columns = range(20) + [\"result\"])\n",
    "\n",
    "# 分析数据集\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#使用pairplot去看两个特征维度下数据的空间分布状况\n",
    "_ = sns.pairplot(df[:50], vars=[8, 11, 12, 14, 19], hue=\"result\", size=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrplot来计算计算各维度特征之间(以及最后的类别)的相关性\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 10))\n",
    "_ = sns.corrplot(df, annot=False)\n",
    "plt.title(u'corrplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.learning_curve import learning_curve\n",
    "#绘制学习曲线，以确定模型的状况\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    画出data在某模型上的learning curve.\n",
    "    参数解释\n",
    "    ----------\n",
    "    estimator : 你用的分类器。\n",
    "    title : 表格的标题。\n",
    "    X : 输入的feature，numpy类型\n",
    "    y : 输入的target vector\n",
    "    ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点\n",
    "    cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份)\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, n_jobs=1, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.xlabel(\"number of Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(\"on\") \n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "#少样本的情况情况下绘出学习曲线\n",
    "plot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0)\",\n",
    "                    X, y, ylim=(0.8, 1.01),\n",
    "                    train_sizes=np.linspace(.05, 0.2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "#训练集上的准确度远高于交叉验证集。这其实意味着我们的模型处于过拟合的状态\n",
    "#增大训练集\n",
    "plot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0)\",\n",
    "                    X, y, ylim=(0.8, 1.1),\n",
    "                    train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#减少特征量\n",
    "#手动选择特征\n",
    "plot_learning_curve(LinearSVC(C=10.0), \"LinearSVC(C=10.0) Features: 11&19\",\n",
    "                    X[:, [11, 19]], y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自动选择最好的特征组合\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# SelectKBest(f_classif, k=2) 会根据Anova F-value选出 最好的k=2个特征\n",
    "\n",
    "plot_learning_curve(Pipeline([(\"fs\", SelectKBest(f_classif, k=2)),\n",
    "                              # select two features\n",
    "                               (\"svc\", LinearSVC(C=10.0))]), \n",
    "                    \"SelectKBest(..., k=2) + LinearSVC(C=10.0)\",\n",
    "                    X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen parameter on 100 datapoints: {'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#手动调整C参数\n",
    "plot_learning_curve(LinearSVC(C=0.1), \"LinearSVC(C=0.1)\",\n",
    "                    X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#自动寻找最适宜参数\n",
    "estm = GridSearchCV(LinearSVC(), \n",
    "                   param_grid={\"C\": [0.001, 0.01, 0.1, 1.0, 10.0]})\n",
    "plot_learning_curve(estm, \"LinearSVC(C=AUTO)\", \n",
    "                    X, y, ylim=(0.8, 1.0),\n",
    "                    train_sizes=np.linspace(.05, 0.2, 5))\n",
    "print \"Chosen parameter on 500 datapoints: %s\" % estm.fit(X[:500], y[:500]).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients learned: [[  0.00000000e+00   0.00000000e+00   0.00000000e+00  -3.22330604e-02\n   -1.66050986e-02   4.41484399e-03  -4.32500490e-02   3.85050275e-02\n    0.00000000e+00   0.00000000e+00   6.27271971e-02   1.22241122e+00\n    1.18931299e-01  -9.43826086e-04   0.00000000e+00   0.00000000e+00\n    0.00000000e+00   0.00000000e+00   9.27643503e-02   0.00000000e+00]]\nNon-zero coefficients: [ 3  4  5  6  7 10 11 12 13 18]\n"
     ]
    }
   ],
   "source": [
    "#l2正则化，它对于最后的特征权重的影响是，尽量打散权重到每个特征维度上，不让权重集中在某些维度上，出现权重特别高的特征。\n",
    "#而l1正则化，它对于最后的特征权重的影响是，让特征获得的权重稀疏化，也就是对结果影响不那么大的特征，干脆就拿不着权重。\n",
    "#l1正则化\n",
    "plot_learning_curve(LinearSVC(C=0.1, penalty='l1', dual=False), \n",
    "                    \"LinearSVC(C=0.1, penalty='l1')\", \n",
    "                    X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))\n",
    "estm = LinearSVC(C=0.1, penalty='l1', dual=False)\n",
    "estm.fit(X[:450], y[:450])  # 用450个点来训练\n",
    "print \"weights learned: %s\" % estm.coef_\n",
    "print \"Non-zero weight columns: %s\" % np.nonzero(estm.coef_)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠拟合定位与解决\n",
    "#构造一份环形数据\n",
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(n_samples=1000, random_state=2)\n",
    "#绘出学习曲线\n",
    "plot_learning_curve(LinearSVC(C=0.25),\"LinearSVC(C=0.25)\",X, y, \n",
    "                    ylim=(0.5, 1.0),train_sizes=np.linspace(.1, 1.0, 5))\n",
    "#训练集上的准确度和交叉验证集上的准确度都很低，这其实就对应了我们说的『欠拟合』状态。\n",
    "#作图进行数据分析\n",
    "data = DataFrame(np.hstack((X, y[:, None])), columns = range(2) + [\"result\"])\n",
    "_ = sns.pairplot(data, vars=[0, 1], hue=\"result\", size=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据根本就没办法线性分割！\n",
    "#解决方法\n",
    "#1...调整你的特征(找更有效的特征！！) \n",
    "# 加入原始特征的平方项作为新特征\n",
    "X_extra = np.hstack((X, X[:, [0]]**2 + X[:, [1]]**2))\n",
    "plot_learning_curve(LinearSVC(C=0.25), \"add feather x1**2+x2**2\", \n",
    "                    X_extra, y, ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2...使用更复杂一点的模型(比如说用非线性的核函数)  rbf\n",
    "from sklearn.svm import SVC\n",
    "# note: 使用原始特征\n",
    "plot_learning_curve(SVC(C=1.5, kernel=\"rbf\", gamma=1.0), \"SVC(C=1.5, kernel='rbf', gamma=1.0)\",X, y,\n",
    "                    ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....关于大数据量情况下的处理方法\n",
    "#生成大样本，高纬度特征数据\n",
    "\n",
    "X, y = make_classification(200000, n_features=200, n_informative=25, n_redundant=0, n_classes=10, class_sep=2, random_state=0)\n",
    "#用SGDClassifier做训练，并画出batch在训练前后的得分差\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "est = SGDClassifier(penalty=\"l2\", alpha=0.001)\n",
    "progressive_validation_score = []\n",
    "train_score = []\n",
    "for datapoint in range(0, 199000, 1000):\n",
    "    X_batch = X[datapoint:datapoint+1000]\n",
    "    y_batch = y[datapoint:datapoint+1000]\n",
    "    if datapoint > 0:\n",
    "        progressive_validation_score.append(est.score(X_batch, y_batch))\n",
    "    est.partial_fit(X_batch, y_batch, classes=range(10))\n",
    "    if datapoint > 0:\n",
    "        train_score.append(est.score(X_batch, y_batch))\n",
    "\n",
    "plt.plot(train_score, label=\"train score\")\n",
    "plt.plot(progressive_validation_score, label=\"progressive validation score\")\n",
    "plt.xlabel(\"Mini-batch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(loc='best')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset consist of 1083 samples with 64 features each\n"
     ]
    }
   ],
   "source": [
    "#可视化\n",
    "#直接从sklearn中load数据集\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "print \"Dataset consist of %d samples with %d features each\" % (n_samples, n_features)\n",
    "\n",
    "# 绘制数字示意图\n",
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(u'the 8*8=64-dimensional digits dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据随机投射到二维坐标上\n",
    "#import所需的package\n",
    "from sklearn import (manifold, decomposition, random_projection)\n",
    "rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)\n",
    "\n",
    "#定义绘图函数\n",
    "from matplotlib import offsetbox\n",
    "import time\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 12})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "       \n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(digits.data.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "#记录开始时间\n",
    "start_time = time.time()\n",
    "X_projected = rp.fit_transform(X)\n",
    "plot_embedding(X_projected, \"Random Projection of the digits (time: %.3fs)\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#降维\n",
    "#PCA降维\n",
    "from sklearn import (manifold, decomposition, random_projection)\n",
    "#TruncatedSVD 是 PCA的一种实现\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "#记录时间\n",
    "start_time = time.time()\n",
    "plot_embedding(X_pca,\"Principal Components projection of the digits (time: %.3fs)\" % (time.time() - start_time))\n",
    "from sklearn import (manifold, decomposition, random_projection)\n",
    "#TSNE降维\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "start_time = time.time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "#绘图\n",
    "plot_embedding(X_tsne,\"t-SNE embedding of the digits (time: %.3fs)\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose loss function\n",
    "\n",
    "xmin, xmax = -4, 4\n",
    "xx = np.linspace(xmin, xmax, 100)\n",
    "plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], 'k-',\n",
    "         label=\"Zero-one loss\")\n",
    "plt.plot(xx, np.where(xx < 1, 1 - xx, 0), 'g-',\n",
    "         label=\"Hinge loss\")\n",
    "plt.plot(xx, np.log2(1 + np.exp(-xx)), 'r-',\n",
    "         label=\"Log loss\")\n",
    "plt.plot(xx, np.exp(-xx), 'c-',\n",
    "         label=\"Exponential loss\")\n",
    "plt.plot(xx, -np.minimum(xx, 0), 'm-',\n",
    "         label=\"Perceptron loss\")\n",
    "\n",
    "plt.ylim((0, 8))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(r\"Decision function $f(x)$\")\n",
    "plt.ylabel(\"$L(y, f(x))$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}